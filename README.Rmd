---
output: github_document
---
```{r setup, include = FALSE}
library(tidyverse)
```

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# elisar

[![Travis-CI Build Status](https://travis-ci.org/koncina/elisar.svg?branch=master)](https://travis-ci.org/koncina/elisar)
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/koncina/elisar?branch=master&svg=true)](https://ci.appveyor.com/project/koncina/elisar)
[![codecov](https://codecov.io/gh/koncina/elisar/branch/master/graph/badge.svg)](https://codecov.io/gh/koncina/elisar)


The goal of elisar is to handle Tecan Sunrise excel exports which were modified to include the plate layout and sample identifications. It will perform a 4PL regression (using the `drc` library) and return a data frame containing the concentrations corresponding to the O.D. values.

## Installation

You can install elisar from github with:

```{r gh-installation, eval = FALSE}
# install.packages("devtools")
devtools::install_github("koncina/elisar")
```

## Example

### Prepare the Excel files

1. Export Tecan sunrise results as MS Excel `.xls` files.
2. Add the layout (column names from `1` to `12` and row names from `A` to `H`) to fill in the IDs for each deposited sample.
    - Plate the layout plate on the same sheet, another sheet in the same file or even in another excel file.
    - The standard values are constructed with a common leading `std_key` id (defaults to `STD` but can be adjusted in the `elisa_analyse()` function) merged to a trailing concentration value. For example: 250, 500 and 1000 pg/ml standard points would be encoded as STD250, STD500 and STD1000 (see wells in rows A-G and columns 11 to 12 in the screenshot below).
3. Add an optional table to extend the identifications. The table should contain the mandatory column `id` listing all IDs reported in the layout. One can add as much columns as required to fully describe the data.

_Example of a modified Excel file: _

![alt text](man/figures/README-xls.png)

### Import the file in _R_

Use the `read_plate()` to read in the O.D. values together with the IDs and extended informations as a data frame.\
A vector containing multiple files can be passed to `read_plate()`: These files can contain multiple data plates (O.D. values) but only a single layout and ID table should be present among all files.

```{r input}
library(tidyverse)
library(elisar)

elisar_example() %>%
  read_plate() %>%
  glimpse()
```

### Perform the regression

```{r analyse}
elisar_example() %>%
  read_plate() %>%
  elisa_analyse() %>%
  glimpse()
```

The `elisa_analyse()` function performs a 4 parameter logistic regression (using `drc::drm()`) and returns a data frame with the calculated concentration values.\
A warning is displayed when O.D. values are outside the standard curve range. These values will be tagged as `FALSE` in the `in_range` column.

The `extract_standard()` function extracts the standard points from the data frame (converting the dose values encoded in the id column to numbers)

```{r, warning = FALSE, message = FALSE}
elisar_example() %>%
  read_plate() %>%
  extract_standard(concentration, od) %>%
  arrange(concentration)
```

To render the regression curve, the output of `extract_standard()` can be used by `ggplot()` (with the `elisar::stat_4pl()` layer to draw the `drc::drm()` 4PL regression model).

```{r standard}
elisar_example() %>%
  read_plate() %>%
  extract_standard() %>%
  ggplot(aes(x = x, y = y)) +
  scale_y_log10() +
  scale_x_log10() +
  annotation_logticks(sides = "lb") +
  geom_point(size = 3, alpha = 0.5) +
  stat_4pl(color = "red", size = 1) +
  labs(title = "Standard curve example",
       x = "Concentration in pg/ml",
       y = "O.D. value") +
  theme_classic()
```

